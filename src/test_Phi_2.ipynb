{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\NVIDIA_contest\\NVIDIA_CONTEST\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "tokenizer_config.json: 100%|██████████| 7.34k/7.34k [00:00<00:00, 7.45MB/s]\n",
      "d:\\NVIDIA_contest\\NVIDIA_CONTEST\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cungh\\.cache\\huggingface\\hub\\models--microsoft--phi-2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "vocab.json: 100%|██████████| 798k/798k [00:01<00:00, 758kB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 574kB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:01<00:00, 1.42MB/s]\n",
      "added_tokens.json: 100%|██████████| 1.08k/1.08k [00:00<00:00, 1.08MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<?, ?B/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "config.json: 100%|██████████| 863/863 [00:00<00:00, 861kB/s]\n",
      "configuration_phi.py: 100%|██████████| 9.26k/9.26k [00:00<00:00, 9.29MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- configuration_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "modeling_phi.py: 100%|██████████| 62.7k/62.7k [00:00<00:00, 20.9MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- modeling_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "model.safetensors.index.json: 100%|██████████| 35.7k/35.7k [00:00<00:00, 132kB/s]\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 5.00G/5.00G [12:54<00:00, 6.45MB/s]\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 564M/564M [01:25<00:00, 6.61MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [14:21<00:00, 430.81s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:41<00:00, 50.68s/it]\n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 124kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../model/phi-2\"\n",
    "tokenizer.save_pretrained(path)\n",
    "model.save_pretrained(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NVIDIA_CONTEST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
